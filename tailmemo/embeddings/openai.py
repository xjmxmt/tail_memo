import os
import warnings
from typing import List, Literal, Optional

from openai import OpenAI

from tailmemo.configs.embeddings.base import BaseEmbedderConfig
from tailmemo.embeddings.base import EmbeddingBase


class OpenAIEmbedding(EmbeddingBase):
    def __init__(self, config: Optional[BaseEmbedderConfig] = None):
        super().__init__(config)

        self.config.model = self.config.model or "text-embedding-3-small"
        self.config.embedding_dims = self.config.embedding_dims or 1536

        api_key = self.config.api_key or os.getenv("OPENAI_API_KEY")
        base_url = (
            self.config.openai_base_url
            or os.getenv("OPENAI_API_BASE")
            or os.getenv("OPENAI_BASE_URL")
            or "https://api.openai.com/v1"
        )
        if os.environ.get("OPENAI_API_BASE"):
            warnings.warn(
                "The environment variable 'OPENAI_API_BASE' is deprecated and will be removed in the 0.1.80. "
                "Please use 'OPENAI_BASE_URL' instead.",
                DeprecationWarning,
            )

        self.client = OpenAI(api_key=api_key, base_url=base_url)

    def embed(self, text, memory_action: Optional[Literal["add", "search", "update"]] = None):
        """
        Get the embedding for the given text using OpenAI.

        Args:
            text (str): The text to embed.
            memory_action (optional): The type of embedding to use. Must be one of "add", "search", or "update". Defaults to None.
        Returns:
            list: The embedding vector.
        """
        text = text.replace("\n", " ")
        return (
            self.client.embeddings.create(input=[text], model=self.config.model, dimensions=self.config.embedding_dims)
            .data[0]
            .embedding
        )

    def embed_batch(self, texts: List[str], memory_action: Optional[Literal["add", "search", "update"]] = None) -> List[List[float]]:
        """
        Get embeddings for multiple texts in a single batch API call.
        
        This is more efficient than calling embed() multiple times as it makes
        a single API request for all texts.

        Args:
            texts (List[str]): The texts to embed.
            memory_action (optional): The type of embedding to use. Defaults to None.
        Returns:
            List[list]: List of embedding vectors in the same order as input texts.
        """
        if not texts:
            return []
        
        # Clean texts
        cleaned_texts = [text.replace("\n", " ") for text in texts]
        
        # Single batch API call
        response = self.client.embeddings.create(
            input=cleaned_texts,
            model=self.config.model,
            dimensions=self.config.embedding_dims
        )
        
        # Return embeddings in the same order as input
        # OpenAI returns embeddings sorted by index
        return [item.embedding for item in sorted(response.data, key=lambda x: x.index)]
